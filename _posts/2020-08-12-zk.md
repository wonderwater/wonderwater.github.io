---
layout: post
title: "zookeeper"
date: 2020-08-12 21:58
categories: "6.824"
tags:
    - distribution
---

6.824 2020 Lecture 8: Zookeeper Case Study

Reading: "ZooKeeper: wait-free coordination for internet-scale systems", Patrick
Hunt, Mahadev Konar, Flavio P. Junqueira, Benjamin Reed.  Proceedings of the 2010
USENIX Annual Technical Conference.


论文说了什么问题？
- 我们能否构建独立通用的服务？Api应该是怎么样的？其他分布式应用怎么用它？
- 为了N倍的副本花了好多钱，那是否可以得到N倍的性能？

首先，性能
至今为止，ZK的服务复制和Raft的模式类似
[clients, leader/state/log, followers/state/log]

我们加更多服务器，副本管理能更快吗？
假设一个繁忙的系统，许多的clients
越多的副本，写操作可能就越慢！因为leader要发生的followers的数量变多了。
那读操作呢？

Q：副本服务只读的client，能否直接操作本地的状态机？而不用协调leader和其他的副本？
那么读操作的容量就是O(#servers)，而不是O(1)

Q：从followers中读操作能否线性化？是否总是读新数据呢？
不是：
- 副本可能并不是majority，所以一些副本看不到全部的完整的写操作。
- 副本副本可能还没提交写操作
- 副本可能和leader隔离了

而可线性化要求不能stale read。

Q：要是client读最新的副本，然后在读滞后的副本？
那可能看到数据回滚了！也是不行的。

Raft和Lab3避免这些问题
- client必须发送给leader，所以lab3是可线性化的，但leader的读负载没法分摊到followers

Zk是怎样处理这个问题的？
改变正确性的定义！运行读旧数据，但维持顺序

顺序保证(Sec2.3)
- 可线性化写：client发送写请求给leader，leader选择一定顺序，记变量“zxid”。发送给副本，所有副本都执行zxid的顺序，和lab类似
- FIFO client顺序：每个client指定操作顺序（读和写）
写：写出现在客户端指定顺序的写序列中，这是业务上的“ready”file（Sec2.3）
读：每个读操作在写顺序的特别点执行。client的后继读要再非降序的点执行，server可能阻塞client的读操作，等待前一个写操作完成，或者sync()调用

为什么这是可行的？
比如，读操作返回旧数据，为什么没问题？从client1看到新数据，然后从client2看到旧数据，为什么没问题？

在更高层次：
对程序员而言，并不难解决，但对性能，可是提高了很多！

为什么ZK即使丢失了部分一致性，依然很有用？
- sync操作让之后client的操作能看到以前处理的写操作。（想看的最新数据时就能派上用场）
- 写操作行为良好，比如排他的test-and-set操作（写操作按真实的顺序，作用最新数据）
- 读操作规则保证“读到自己写的”
- 读操作规则有助推理

1. 例子1：如果看到ready file，后续读看到前一个写，即使client换了server读
```text
         Write order:      Read order:
         delete("ready")
         write f1
         write f2
         create("ready")
                           exists("ready")
                           read f1
                           read f2
```
2. 例子2：在读顺序的写操作之前，已经被之前的写操作触发
```text
         Write order:      Read order:
                           exists("ready", watch=true)
                           read f1
         delete("ready")
         write f1
         write f2
                           read f2
```

一些结果：
- leader要保留client的写操作顺序，即使leader挂了
- 副本必须保证 client的读操作绝不会再zxid顺序上回滚，即使副本失败了
- client必须追踪它读的最高的zxid，保证下一次读不会读到回滚的数据

ZK的其他性能技巧
- client可以发送异步写给leader（async=不用等待返回）
- leader批量发送请求，减少网络和磁盘负载（加上有众多clients）
- 模糊的快照（密等更新），所以快照时，允许写操作

最终的性能好吗？
Table1
高读吞吐量 - server数量增加而增加
更低的写吞吐量 - server数量增加而减小
每秒21000写操作很棒！
- 可能受持久化的磁盘现在
- 比磁盘10ms的写，高了很多 - 批量写

ZK的其他目的：通用的服务
这是关于Api，和Api如果帮助分布式软/硬件的协作
Api应该是怎样的，并不清晰！

我们指的协作的像一个服务是什么意思？

例子：VM-FT的test-and-set服务
- 如果一个副本不能联系另一个，那么抢占t-a-s锁，变成唯一的server
- 必须有排他性，避免出现两个primaries（比如网络分裂时）
- 必须有容错性

例子：GFS（更明显）
- 可能是共识：元数据的那个副本是master
- 可能是记录chunk servers记录的，那个chunk是primary

其他例子：MapReduce, YMB, Crawler等，
谁是master；worker列表；labor划分；任务状态。

一个通用性的服务可以更省心！

可以用lab3 k/v存储作为通用协调的服务吗？

比如，当多个副本要接管服务，选择新GFS的master时？
可能的步骤：
```text
Put("master", my IP address)
if Get("master") == my IP address:
      act as master
```

问题:竞争的put可能在一组put\get后执行，导致出现两个master。
所以这并不是很好的Api设计

要独占性！
- 问题：master挂了应该做什么？也许master应该定时的刷新put方法，这会有大量请求
- 问题：client如何知道master改变了？周期性调用get？这会有大量请求

## ZK Api一览(Figure 1)

状态：类似文件系统的znodes
文件名，文件内容，文件夹，路径名称
典型用法：znodes存配置信息
- 应用关联的一组机器
- 那个机器是primary

每个znode都有版本号
znode类型：
- regular常规的
- ephemeral零时的
- sequential: name + seqno顺序的


znodes的操作（Sec2.2）
- create(path, data, flags)
  exclusive -- 第一个创建的才会成功
- delete(path, version)
  if znode.version = version, then delete
- exists(path, watch)
  watch=true：如果path之后被删除/创建会发送通知
- getData(path, watch)
- setData(path, data, version)
  if znode.version = version, then update
- getChildren(path, watch)
- sync()
  先sync在read，保证对同一个client，在sync之前的写操作，read都能看到
  client可以当作提交写
  
ZK api对协调同步操作设计良好
- 独占文件的创建：并发中只有一个创建请求会成功
- getData()/setData(x, version)支持mini事务
- client失败时，session自动操作（比如失败时释放锁）
- 多个clients，序列文件创建的顺序
- watch——避免轮询

例子：在ZK的znode中某数字+1
- 要是read返回过时的数据？写操作就可能写错误的值
- 要是另一个client并发更新？那个+1操作会丢失？
```text
  while true:
    x, v := getData("f")
    if setData(x + 1, version=v):
      break
```
这就是mini事务，提供原子的read-modify-write
其他变种，比如test-and-set for VMware-FT

例子：简单锁（Sec2.4）
```text
  acquire():
    while true:
      if create("lf", ephemeral=true), success
      if exists("lf", watch=true)
        wait for notification

  release(): (voluntarily or session timeout)
    delete("lf")
```
Q：如果调用exists之前，释放锁，那该怎么办？

例子：不引发群效应的锁(Sec2.4伪代码)

1. create a "sequential" file
2. list files
3. if no lower-numbered, lock is acquired!
4. if exists(next-lower-numbered, watch=true)
5.   wait for event...
6. goto 2

Q: 步骤2、3之间是否可能有更低的数字被创建？
Q: client轮到turn之前，会触发watch吗？
A: yes
```text
lock-10 <- current lock holder
lock-11 <- next one
lock-12 <- my request
```
如果创建lock-11的客户端在获取锁前挂了，watch会被触发，但不是my turn

## 使用锁
- 和单个机器的线程锁有区别！
1. 如果lock持有者挂了，系统将自动释放锁
2. 所以锁实际上并没有强制其他活动的原子性。
3. 为了写的原子性，用“ready”技巧或mini事务
- 对master/leader选举很有用
新leader必须要检查状态和做清理，或者为了性能牺牲正确性，使用soft lock。
比如：只有一个worker做每个Map、Reduce任务（多个done也没事）
比如：只有一个worker抓一个URL（多个done也没事）

## ZK是成功的设计
ZK的Wikipedia列出多个项目正在使用它
很少消除分布式中的复杂性
- 比如GFS的master依然需要复制文件元数据
- noriGFS的primary依然要计划复制chunks

但确实解决了一些常见问题：
- master选举
- 持久化mster状态（如果状态数据小）
- 谁是当前的master（name服务）
- worker注册
- 任务队列

## 未涵盖的话题：
- 持久性
- 为性能的批量、流水线技术细节
- 模糊快照
- 幂等操作
- 重复client请求检测

## 引用

- https://zookeeper.apache.org/doc/r3.4.8/api/org/apache/zookeeper/ZooKeeper.html
- ZAB: http://dl.acm.org/citation.cfm?id=2056409
- https://zookeeper.apache.org/
- https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf  (wait free, universal objects, etc.)































