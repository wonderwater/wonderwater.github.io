---
layout: post
title: "一致性协议raft2"
date: 2020-07-25 10:30
categories: "6.824"
tags:
    - distribution
    - algorithm
---

本节：raft持久化、客户端行为、快照

# topic：Raft log（Lab2B）

## leader的作用：
client只能和leader交互，
client看不到followers状态和logs

## 当换leader时，会发生什么
比如：老leader挂了

换leader，怎样不会发生奇怪的事？
分叉的复制、丢失操作、重复操作等

## 我们想要什么？
如果任何一个server执行了log entry的一个给定的指令，那么不会有server，在同一个log entry执行别的指令（Figure 3's State Machine Safety）

为什么？如果servers在某个操作达成共识，那么leader的改变可能造成client可视状态的改变，将违反看起来像一个server的目标

比如：

    S1: put(k1,v1) | put(k1,v2) 
    S2: put(k1,v1) | put(k2,x) 
    不能允许他们执行第二个log entries
    
## 奔溃后，logs会有怎样的不一致？
在发AppendEntries前奔溃的状态：

    S1: 3
    S2: 3 3
    S3: 3 3

糟糕的情况：相同的entries有不同的指令！经过一系列的leader挂掉。比如
```text
        10 11 12 13  <- log entry #
    S1:  3
    S2:  3  3  4
    S3:  3  3  5
```

## Raft通过强迫followers接受新leader的log，达到共识
例子：
```text

S3是term6的leader
S3发AppendEntries，entry13，prevLogIndex=12，prevLogTerm=5
S2回复false
S3减少nextIndex[S2]，设为12
S3再发AppendEntries，entry12和13，prevLogIndex=11，prevLogTerm=3
S2删掉entry12，添加S3的entry12和13

S1也是相似的，但S3需要再退一步
```

## 回滚的结果：
在线的followers删掉尾部和leader不同的log，然后在与leader一致的log后，添加leader的entries

Q:为什么S2删掉index=12 term=4的entry没有问题？

## 新leader会不会回滚掉先前term的已提交的entries？
比如：新leader的log，会不会缺少之前已提交的entry？

那就是灾难了：因为老leader已经回复给client "yes"了，
所以，Raft需要保证被选举的新leader必须包含所有已提交的log entries

## 为什么不采用最长log的server为leader的策略？
例子
```text
    S1: 5 6 7
    S2: 5 8
    S3: 5 8
```
首先，怎么构造这个场景？term6，S1是leader，然后挂了重启，但在term7，S1又被选为leader，然后又挂，
接着另外两台某台被选为leader，添加了log。

Q：term7时，S1挂了后，为什么S2、S3不是用term6选举？而变成了term8？

A：因为S2、S3中，至少有一台为term7阶段投过票

所有机子重启，谁会是下一个leader？
S1有最长的log，但entry8已经提交！所以新leader只能是S2或S3。
这也解释了为什么不采用最长log的server为leader的策略

## 论文5.4.1最后解释了"election restriction"

RequestVote投的candidate要至少足够新（at least as up to date）
- candidate最后的entry的term更大，或者
- candidate有一样的term，并且有相同或更长的log

所以S2、S3不会投给S1；S2、S3只能相互投，那就是S2、S3能选为leader，S1要抛弃entries 6、7

6、7并不是大多数 -> 没有提交 -> 没有响应给clients -> client需要重发指令

## 小结
至少足够新规则保证新leader的log包含全部提交的entries，所以新leader不会回滚任何已提交指令

## 上一节的问题
figure 7，top server挂了，谁当选？

![](/pic/202007/2020-07-25-14.28.58.png)

## 取决于谁当选，不同的entries将被提交或抛弃
但有些始终会提交的：111445566，他们应该已经提交、执行、回复了。

一些确定被抛弃的：f的2和3；e的最后：4、4；

c的6、6；d的7，7可能会被抛弃或提交

## 如何快速回滚？
按照Figure2的设计，回滚是很慢的。lab tester要求快速回滚

论文在5.3大致描绘了这一思想，但没有细节。下面是我的猜想，可能有更好的办法。
```text
      Case 1      Case 2       Case 3
  S1: 4 5 5       4 4 4        4
  S2: 4 6 6 6 or  4 6 6 6  or  4 6 6 6
```

S2是term6的leader，S1开始服务后，S2发AE，prevLogTerm=6

S1的返回false，还要包含：
    XTerm:  term in the conflicting entry (if any)
    XIndex: index of first entry with that term (if any)
    XLen:   log length

Case1: 没有XTerm的情况：nextIndex = XIndex
Case2: 有XTerm的情况：nextIndex=leader的Xterm的最后一个entry
Case3: follower太短的情况：nextIndex = XLen

# topic：持久化（lab2C）

问题：log会变得很庞大：比应用的状态机都大，重启后或者新server，将会耗费不小的时间replay

幸运的是：server运行，并不需要完整的log、服务状态机都满足
    部分log的执行已经应用到状态机了
    client只看到状态机的，并不是log
服务状态机通常更小，所以我们选维护服务状态机。

## 哪些entries是能丢的？
1. 未执行的entries - 只是还没应用到状态机
2. 未提交的entries - 也许得到大多数回复了

解决方案：服务周期性创建持久化的快照（snapshot）
  [diagram: service state, snapshot on disk, raft log (same in mem and disk)]

- 把服务状态当做执行的特别的log entry，比如k/v表
- 服务写入快照到持久化存储（磁盘）
- Raft丢弃索引之前的log
- 服务可以在任意时刻创建快照，删除之前的log，比如log太长的时候

## 故障重启怎么操作？
服务从磁盘读取快照，Raft从磁盘读取持久化的log。
服务告诉Raft设置lastAppled为最后一个索引，避免replay已经应用的log entries

## 问题：要是followers的log的尾端，比leader的log头部还小？
因为followers可能在leader丢弃部分log时离线了。

nextIndex[i]设为leader的头部log，这样在做InstallSnapshot时，不会被AppendEntries干扰

## 哲学观点：
状态经常等同于操作历史的总和，你能经常选择其一，去存储或通信。之后我们将看到更多这种二元性的例子

## 物理观点：
Raft的快照模式是因为状态机小，对于大DB，比如复制的数据数G以上，那么写磁盘就慢了。

可能服务数据在磁盘应该以B-Tree存储，不需要显示的快照，因为磁盘足够了。

处理延迟的log确实难，虽然leader应该将log保存一会，或是要记得已经应用到状态机的部分

## 可线性化（linearizability）

## 我们需要证明正确性（为Lab3等）
client期待的Put、Get的行为应该是怎样的？

一般称为一致性约束（consistency contract），
帮助我们了解怎么样处理复杂情况的正确性，比如并发，复杂，故障，RPC重发，leader变更、优化。
课程后面将看到更多一致性定义

可线性化最常用的，直觉的定义：表现的像单台机子的行为（"强"一致性）

可线性化定义：
执行历史是可线性化的如果：
1. 为全部操作，找到一个统一的顺序，
2. 可以匹配真实（real-time）的时序（没有重叠的操作），
3. 且读操作可以看到
4. 在这种顺序下之前的写操作的结果

这个历史就是client操作的记录，带有参数、返回值、开始时间、完成时间

## 例子1
```text
  |-Wx1-| |-Wx2-|
    |---Rx2---|
      |-Rx1-|
```
Wx1表示向x，写1；Rx1表示读x，结果是1

画约束箭头：

值约束，W->R（value）；
遵循真实的时序，Wx1 -> Wx2（time）

那么结果是Wx1 Rx1 Wx2 Rx2，所以是可线性化的


## 例子2

```text
  |-Wx1-| |-Wx2-|
    |--Rx2--|
              |-Rx1-|

```
画约束箭头：

  Wx1 before Wx2 (time)
  Wx2 before Rx2 (value)
  Rx2 before Rx1 (time)
  Rx1 before Wx2 (value)

存在一个环（Wx2 Rx2 Rx1），所以不能转为线性，是不可线性化的。

## 例子3
```text
|--Wx0--|  |--Wx1--|
            |--Wx2--|
        |-Rx2-| |-Rx1-|
```
顺序：Wx0 Wx2 Rx2 Wx1 Rx1，可线性化的。

所以服务能挑任一组顺序并发写，比如Raft向log放入并发的操作

## 例子4
```text
|--Wx0--|  |--Wx1--|
            |--Wx2--|
C1:     |-Rx2-| |-Rx1-|
C2:     |-Rx1-| |-Rx2-|
```
  Wx2 then C1:Rx2 (value)
  C1:Rx2 then Wx1 (value)
  Wx1 then C2:Rx1 (value)
  C2:Rx1 then Wx2 (value)
  
存在一个环，是不可线性化的。

所以：服务对于并发写入可以选择任意顺序，但所有的client必须以同一顺序看到写的结果。

我们在复制和缓存时，要对所有操作在顺序上达成一致。

## 例子5
```text
|-Wx1-|
        |-Wx2-|
                |-Rx1-|
```
  Wx2 before Rx1 (time)
  Rx1 before Wx2 (value)
(或：时间约束意味着唯一可能的顺序是Wx1 Wx2 Rx1)

存在一个环，是不可线性化的。

所以，读必须返回刷新的数据：旧值是不可线性化的，即使读client不知道写，时间规则要求读要返回最新的数据。

可线性化要求防止了许多的情况发生：
- 脑裂（两个活动的leaders）
- 重启后，丢失提交的写
- 从延迟的副本读取

## 例子6
设想client没有得到请求，于是重新请求。

这种情况下，返回丢失的：leader要记住client的请求，
如果发现请求重复，直接返回第一次执行后保存下来的返回结果

但可能会返回一个很久以前保存的值--旧值！

对可线性化的影响？
```text
C1: |-Wx3-|          |-Wx4-|
C2:          |-Rx3-------------|
```
顺序：Wx3 Rx3 Wx4

所以返回旧值3，是正确的

更多信息：https://www.anishathalye.com/2017/06/04/testing-distributed-systems-for-linearizability/


# 重复的RPC检测（Lab 3）

## client请求Put或Get，RPC超时了怎么办？
比如：Call()返回false。
- server挂了或请求丢失：重发
- 如果server已经执行，但请求丢失：重发就有问题了

问题：
这两种情况client分辨不了，所以即使执行了，client也要得到回复

## 想法：重复的RPC检测
如果k/v服务可以检测重复的client请求，client可以放个id进请求里，同一个id代表重发的RPC请求。

k/v服务维护id的索引表，每个RPC执行后记录这个请求，第二个相同id请求来时，则是重复的，从索引表生成回复数据即可。

问题：何时删除索引表？如果leader变了，如何拿到索引表？如果server挂了，如何恢复索引表？

想法：使保存索引表小

索引表中每项是client，而不是每个RPC，每个client一次只发一个RPC，且每个client的发的RPC是顺序的，
当收到client的RPC#10，丢掉之前的索引的entries，因为这表示client不会重发之前的RPC请求了

细节：
- 每个client需要唯一的client ID，比如64位随机数
- client发送RPC中，带有client ID和seq #，重发的seq #不变。
- 防重的索引表（在k/v层）通过client ID索引，如果已经该请求执行过了，就会有seq#和值
- 每个log entries都要记录clientID, seq#
- 当applyCh得到一个操作时，更新防重索引表client，对应client的seq#和值，唤醒等待的RPC

## 要是在请求执行完成前，重复的请求到达了，怎么办？
调用Start()（又一次），那么log中可能就会出现两次（相同clientID，相同的seq#）,那么传到applyCh时，如果防重索引表中存在，则忽略

## 新leader怎么得到防重表？
所有的副本在执行指令时，都要更新防重表，那么新leader当选时，就有了重复表的信息了

## 故障恢复时，怎样恢复防重表？
- 如果没快照，replay log，更新防重表
- 如果有快照，快照必须包含这张表

但是，k/v服务从防重表中返回旧值，要是replay的值是过时的，有影响吗？

## 例子

```text
  C1           C2
  --           --
  put(x,10)
               first send of get(x), 10 reply dropped
  put(x,20)
               re-sends get(x), gets 10 from table, not 20
```
可线性化视图：
```text
C1: |-Wx10-|          |-Wx20-|
C2:          |-Rx10-------------|
order: Wx10 Rx10 Wx20
```
所以返回10是正确的。

# 只读操作（论文Sec8末尾）
Q：一个只读操作，比如Get(key)，在leader得到大多数响应前，可以提交吗？
也就是：leader能用当前k/v表数据直接返回Get操作的结果吗？

A：不行，无论是Figure 2描述的，还是实验里，都不行。
设想S1是leader，得到Get(k)，S1可能会由于网络问题，丢失选期，并且感知不到。
新leader，比如S2，可能已经处理了k键的Put操作，所以S1的k/v表是过时的了，
使用过时的数据是不可线性化的，这就是脑裂的现象。

所以，Figure 2要求Get() 也要提交到log。
如果leader可以提交这个Get()，那么再log的这个位置插入时，它应该还是leader。
如果发生S1的情况，不晓得已经丢失选期，那就得不到大多数AppendEntries的响应，
也就不会提交Get()，也就不会响应client成功。

但是，大多应用是读操作频繁，而提交Get()太费时间，是否读操作可以避免提交呢？
实践中，有一个很棒的想法。

## 想法：租约（leases）
修改Raft协议：
- 定义一个租约周期，比如5s
- 每次leader得到大多数AppendEntries回应，
说明在租期内，读请求有资格响应给client，不用做提交，比如发提交的AppendEntries
- 新leader在前一个租约过期前，不能做Put()操作
- 所以follows要保存最后一次回复AppendEntries的时间，并在选举的时候告诉新leader

最后，更快的只读操作，且可线性化。

实践里，人们更愿意为了高性能，容忍读过时的数据。
